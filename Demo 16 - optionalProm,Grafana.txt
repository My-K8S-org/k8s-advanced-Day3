
Step 1:
#minikube status
#open cmd prompt
#mkdir prometheus
#cd prometheus
#git clone https://github.com/dhanan77/k8s-prometheus/upload

Step 2:
#kubectl config use-context minikube
#kubectl apply -f monitoring-namespace.yaml
#kubectl get ns.

Step 3:
#kubectl apply -f prometheus-config.yaml
#kubectl get configmap --namespace=monitoring prometheus-config -o yaml

Step 4:
#kubectl apply -f prometheus-deployment.yaml
#kubectl get deployments --namespace=monitoring

Step 5:
#kubectl apply -f prometheus-service.yaml
#kubectl get services --namespace=monitoring prometheus -o yaml
#minikube service prometheus -n monitoring

From the Prometheus console, you can explore the metrics is it collecting and 
do some basic graphing. You can also view the configuration and the targets. 
Click Status->Targets and you should see the Kubernetes cluster and nodes. 
You should also see that Prometheus discovered itself under kubernetes-pods.

Step 6:
#kubectl apply -f grafana-deployment.yaml
#kubectl apply -f grafana-service.yaml

#minikube service --namespace=monitoring grafana
Username is admin and password is also admin

Step 7:
In the Graphana Page:
Let's add Prometheus as a datasource.

Click on the icon in the upper left of grafana and go to "Data Sources".
Click "Add data source".
For name, just use "prometheus"
Select "Prometheus" as the type
For the URL, we will actual use Kubernetes DNS service discovery. 
So, just enter http://prometheus:9090. 
Create a New dashboard by clicking on the upper-left icon and 
selecting Dashboard->New. 
Click the green control and add a graph panel. 
Under metrics, select "prometheus" as the datasource. 
For the query, use sum(container_memory_usage_bytes) by (pod_name). 
Click save. This graphs the memory used per pod.

Step 8:
Now , Lets add DaemonSet here.
#  kubectl apply -f node-exporter-daemonset.yml 

After a minute or so, Prometheus will discover the node 
itself and begin collecting metrics from it. 
In Prometheus page , use node_load1 as the metric query. 
This will be the one minute load average of the nodes.

